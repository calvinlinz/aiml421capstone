{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1492 images from cherry class.\n",
      "Loaded 1494 images from strawberry class.\n",
      "Loaded 1494 images from tomato class.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define the classes\n",
    "classes = ['cherry', 'strawberry', 'tomato']\n",
    "data_dir = './train_data'\n",
    "\n",
    "# Dictionary to store the loaded images\n",
    "data = {}\n",
    "\n",
    "# List of images to exclude\n",
    "excluded_images = {\n",
    "    'cherry_0055.jpg',\n",
    "    'cherry_0105.jpg',\n",
    "    'cherry_0147.jpg',\n",
    "    'strawberry_0931.jpg',\n",
    "    'tomato_0087.jpg'\n",
    "}\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    images = []\n",
    "    \n",
    "    # Loop through all files in the class directory\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        if file_name.endswith('.jpg'):  # Check for image files\n",
    "            # Check if the file should be excluded\n",
    "            if file_name in excluded_images:\n",
    "                continue  # Skip this file\n",
    "            file_path = os.path.join(class_dir, file_name)\n",
    "            \n",
    "            # Open the image and append it to the list\n",
    "            img = Image.open(file_path)\n",
    "            images.append(img)\n",
    "    \n",
    "    # Store images for this class\n",
    "    data[class_name] = images\n",
    "\n",
    "\n",
    "# Example: Accessing images from the 'cherry' class\n",
    "print(f'Loaded {len(data[\"cherry\"])} images from cherry class.')\n",
    "print(f'Loaded {len(data[\"strawberry\"])} images from strawberry class.')\n",
    "print(f'Loaded {len(data[\"tomato\"])} images from tomato class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 1475 images from cherry class.\n",
      "Filtered 1477 images from strawberry class.\n",
      "Filtered 1476 images from tomato class.\n",
      "Removed 52 images in total.\n",
      "Filtered 4428 images in total.\n"
     ]
    }
   ],
   "source": [
    "# Define the target resolution\n",
    "target_size = (300, 300)\n",
    "\n",
    "# Dictionary to hold filtered data\n",
    "filtered_data = {}\n",
    "\n",
    "count = 0\n",
    "# Iterate through the classes\n",
    "for class_name, images in data.items():\n",
    "    filtered_images = []\n",
    "    \n",
    "    # Check each image for its resolution\n",
    "    for img in images:\n",
    "        if img.size == target_size:\n",
    "            filtered_images.append(img)  # Keep images that match 300x300\n",
    "        else:\n",
    "            count += 1\n",
    "    \n",
    "    # Store only the filtered images in the new dictionary\n",
    "    filtered_data[class_name] = filtered_images\n",
    "\n",
    "# Example: Accessing filtered images\n",
    "print(f'Filtered {len(filtered_data[\"cherry\"])} images from cherry class.')\n",
    "print(f'Filtered {len(filtered_data[\"strawberry\"])} images from strawberry class.')\n",
    "print(f'Filtered {len(filtered_data[\"tomato\"])} images from tomato class.')\n",
    "print(f'Removed {count} images in total.')\n",
    "print(f'Filtered {len(filtered_data[\"cherry\"])+len(filtered_data[\"strawberry\"])+len(filtered_data[\"tomato\"])} images in total.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images: 4428\n",
      "Processed images: 4427\n",
      "Removed Grayscale images: 1\n",
      "RGB images: 4426\n",
      "Outliers: 144\n",
      "Images in filtered_data: 4283\n",
      "\n",
      "Found 144 potential RGB channel-based outliers out of 4427 total images.\n",
      "Filtered data contains 4283 images after RGB channel-based filtering.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def detect_and_filter_rgb_outliers(image_data, thresholds):\n",
    "    filtered_data = defaultdict(list)\n",
    "    outliers = []\n",
    "    grayscale_count = 0\n",
    "    total_input_images = sum(len(images) for images in image_data.values())\n",
    "    \n",
    "    for class_name, images in image_data.items():\n",
    "        for img in images:\n",
    "            img_np = np.array(img)  # Convert image to NumPy array\n",
    "            \n",
    "            if len(img_np.shape) == 2:  # Grayscale image (only height and width)\n",
    "                grayscale_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Calculate the mean pixel intensity for each RGB channel\n",
    "            mean_channels = np.mean(img_np, axis=(0, 1))\n",
    "            \n",
    "            # Detect if any of the channels are outside their specific thresholds\n",
    "            condition = (mean_channels < [t[0] for t in thresholds]) | (mean_channels > [t[1] for t in thresholds])\n",
    "            if np.any(condition):\n",
    "                outliers.append(img)\n",
    "            else:\n",
    "                filtered_data[class_name].append(img)\n",
    "    \n",
    "    total_processed_images = sum(len(images) for images in filtered_data.values()) + len(outliers)\n",
    "    \n",
    "    print(f\"Input images: {total_input_images}\")\n",
    "    print(f\"Processed images: {total_processed_images}\")\n",
    "    print(f\"Removed Grayscale images: {grayscale_count}\")\n",
    "    print(f\"RGB images: {total_processed_images - grayscale_count}\")\n",
    "    print(f\"Outliers: {len(outliers)}\")\n",
    "    print(f\"Images in filtered_data: {sum(len(images) for images in filtered_data.values())}\")\n",
    "    \n",
    "    return dict(filtered_data), outliers\n",
    "\n",
    "# Define channel-specific thresholds based on the distributions\n",
    "thresholds = [\n",
    "    (27, 238),  # Red channel (low, high)\n",
    "    (14, 220),  # Green channel (low, high)\n",
    "    (8, 218)    # Blue channel (low, high)\n",
    "]\n",
    "\n",
    "# Use the optimized function with new thresholds\n",
    "filtered_data, rgb_outliers = detect_and_filter_rgb_outliers(filtered_data, thresholds)\n",
    "print(f'\\nFound {len(rgb_outliers)} potential RGB channel-based outliers out of {sum(len(images) for images in filtered_data.values()) + len(rgb_outliers)} total images.')\n",
    "print(f'Filtered data contains {sum(len(images) for images in filtered_data.values())} images after RGB channel-based filtering.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X shape: torch.Size([2998, 3, 300, 300]), Training y shape: torch.Size([2998])\n",
      "Testing X shape: torch.Size([1285, 3, 300, 300]), Testing y shape: torch.Size([1285])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/pkg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "def normalize(data):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts image to tensor and normalizes to [0, 1]\n",
    "    ])\n",
    "    X_data = []\n",
    "    y_labels = []\n",
    "\n",
    "    label_mapping = {\n",
    "        'cherry': 0,\n",
    "        'strawberry': 1,\n",
    "        'tomato': 2\n",
    "    }\n",
    "\n",
    "    # Step 1: Transform images directly without intermediate NumPy conversion\n",
    "    for label, images in data.items():\n",
    "        for img in images:\n",
    "            img_transformed = transform(img)  # Apply transformation to normalize and convert to tensor\n",
    "            X_data.append(img_transformed)\n",
    "            y_labels.append(label_mapping[label])\n",
    "\n",
    "    # Step 2: Stack tensors together\n",
    "    X = torch.stack(X_data)  # Now, X will be of shape [num_images, 3, 300, 300]\n",
    "    y = torch.tensor(y_labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_dataloaders():\n",
    "    X_train, X_test, y_train, y_test = normalize(filtered_data)\n",
    "    # Step 4: Create TensorDatasets and DataLoaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=24)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=24)\n",
    "    # Check shapes\n",
    "    print(f\"Training X shape: {X_train.shape}, Training y shape: {y_train.shape}\")\n",
    "    print(f\"Testing X shape: {X_test.shape}, Testing y shape: {y_test.shape}\")\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # First convolutional layer: input channels=3, output channels=16, kernel size=3x3\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Max pooling layer to downsample\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 75 * 75, 128)  # Adjusting for 300x300 input size after pooling\n",
    "        self.fc2 = nn.Linear(128, 3)  # Output size matches the number of classes (cherry, strawberry, tomato)\n",
    "        \n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first conv layer, activation, and pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        \n",
    "        # Apply second conv layer, activation, and pooling\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the output from convolutional layers\n",
    "        x = x.view(-1, 32 * 75 * 75)\n",
    "        \n",
    "        # Apply fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:39:35,929] A new study created in memory with name: no-name-7cbd7e3c-1b1c-4ccd-a846-355e5baaec54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:40:33,596] Trial 0 finished with value: 58.00612131329994 and parameters: {'num_epochs': 6}. Best is trial 0 with value: 58.00612131329994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:42:16,864] Trial 1 finished with value: 57.104730105731775 and parameters: {'num_epochs': 11}. Best is trial 0 with value: 58.00612131329994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:44:18,516] Trial 2 finished with value: 57.470840289371175 and parameters: {'num_epochs': 13}. Best is trial 0 with value: 58.00612131329994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:45:25,021] Trial 3 finished with value: 57.805230940456305 and parameters: {'num_epochs': 7}. Best is trial 0 with value: 58.00612131329994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:46:40,759] Trial 4 finished with value: 59.47262103505843 and parameters: {'num_epochs': 8}. Best is trial 4 with value: 59.47262103505843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:48:33,353] Trial 5 finished with value: 57.77250973845298 and parameters: {'num_epochs': 12}. Best is trial 4 with value: 59.47262103505843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:50:56,433] Trial 6 finished with value: 57.17239844184752 and parameters: {'num_epochs': 15}. Best is trial 4 with value: 59.47262103505843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:52:02,836] Trial 7 finished with value: 59.27239844184752 and parameters: {'num_epochs': 7}. Best is trial 4 with value: 59.47262103505843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:54:23,074] Trial 8 finished with value: 58.138452977184194 and parameters: {'num_epochs': 15}. Best is trial 4 with value: 59.47262103505843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:55:11,135] Trial 9 finished with value: 57.70456316082359 and parameters: {'num_epochs': 5}. Best is trial 4 with value: 59.47262103505843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_epochs': 8}\n",
      "Best cross-validation accuracy: 59.47262103505843\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "def train_and_evaluate(train_loader, val_loader, model, optimizer, device, num_epochs):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_acc\n",
    "\n",
    "# Hyperparameter optimization using Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameter search space\n",
    "    k_folds = 5\n",
    "    num_epochs = trial.suggest_int('num_epochs', 5, 15)\n",
    "    # batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Get dataset from the DataLoader\n",
    "    dataset = train_loader.dataset\n",
    "    num_samples = len(dataset)\n",
    "    indices = list(range(num_samples))\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "        print(f'Fold {fold + 1}')\n",
    "        \n",
    "        # Create data samplers and loaders for this fold\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_fold_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "        val_fold_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n",
    "        \n",
    "        # Initialize model and optimizer\n",
    "        model = CNN()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00020711569050274695)\n",
    "        \n",
    "        # Train and evaluate\n",
    "        val_accuracy = train_and_evaluate(train_fold_loader, val_fold_loader, model, optimizer, device, num_epochs)\n",
    "        fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Return the mean accuracy across folds for the trial\n",
    "    return np.mean(fold_accuracies)\n",
    "\n",
    "# Create study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Best hyperparameters\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "\n",
    "# Best result\n",
    "print('Best cross-validation accuracy:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion = nn.CrossEntropyLoss(), lr=0.001, num_epochs=10, flatten=False):\n",
    "    # Define loss function and optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            # Flatten the input images\n",
    "            if flatten:\n",
    "                data = data.view(data.size(0), -1)  # [batch_size, 270000]\n",
    "\n",
    "            # Forward pass: compute predictions\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass: compute gradients\n",
    "            optimizer.zero_grad()  # Clear the previous gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print average loss for the epoch\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    print(\"Training complete!\")\n",
    "    return model\n",
    "\n",
    "def get_trained_mlp(train_loader):\n",
    "    # Define input, hidden, and output sizes\n",
    "    input_size = 3 * 300 * 300  # 270,000 for RGB images\n",
    "    hidden_size = 128  # You can tune this based on your needs\n",
    "    output_size = 3  # 3 classes: 'cherry', 'strawberry', 'tomato'\n",
    "    # Instantiate the model\n",
    "    model = MLP(input_size, hidden_size, output_size)\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "    return train(model, train_loader, criterion, lr=0.001, num_epochs=10, flatten=True)\n",
    "\n",
    "def get_trained_cnn(train_loader):\n",
    "    model = CNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return train(model, train_loader, criterion, lr=0.001, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, flatten=False):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:  # Use your test DataLoader here\n",
    "            if flatten:\n",
    "                data = data.view(data.size(0), -1)\n",
    "            # Forward pass: compute predictions\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Get the predicted class by finding the index of the max log-probability\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Update total number of predictions\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Update correct predictions\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.3187\n",
      "Epoch [2/10], Loss: 0.9767\n",
      "Epoch [3/10], Loss: 0.8843\n",
      "Epoch [4/10], Loss: 0.7759\n",
      "Epoch [5/10], Loss: 0.6191\n",
      "Epoch [6/10], Loss: 0.4500\n",
      "Epoch [7/10], Loss: 0.2706\n",
      "Epoch [8/10], Loss: 0.1692\n",
      "Epoch [9/10], Loss: 0.0936\n",
      "Epoch [10/10], Loss: 0.0474\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "cnn_model = get_trained_cnn(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 64.67%\n"
     ]
    }
   ],
   "source": [
    "test_model(cnn_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
