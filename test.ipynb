{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define the classes\n",
    "classes = ['cherry', 'strawberry', 'tomato']\n",
    "data_dir = './train_data'\n",
    "\n",
    "# Dictionary to store the loaded images\n",
    "data = {}\n",
    "\n",
    "# List of images to exclude\n",
    "excluded_images = {\n",
    "    'cherry_0055.jpg',\n",
    "    'cherry_0105.jpg',\n",
    "    'cherry_0147.jpg',\n",
    "    'strawberry_0931.jpg',\n",
    "    'tomato_0087.jpg'\n",
    "}\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    images = []\n",
    "    \n",
    "    # Loop through all files in the class directory\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        if file_name.endswith('.jpg'):  # Check for image files\n",
    "            # Check if the file should be excluded\n",
    "            if file_name in excluded_images:\n",
    "                continue  # Skip this file\n",
    "            file_path = os.path.join(class_dir, file_name)\n",
    "            \n",
    "            # Open the image and append it to the list\n",
    "            img = Image.open(file_path)\n",
    "            images.append(img)\n",
    "    \n",
    "    # Store images for this class\n",
    "    data[class_name] = images\n",
    "\n",
    "\n",
    "# Example: Accessing images from the 'cherry' class\n",
    "print(f'Loaded {len(data[\"cherry\"])} images from cherry class.')\n",
    "print(f'Loaded {len(data[\"strawberry\"])} images from strawberry class.')\n",
    "print(f'Loaded {len(data[\"tomato\"])} images from tomato class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def detect_and_filter_rgb_outliers(image_data, thresholds):\n",
    "    filtered_data = defaultdict(list)\n",
    "    outliers = []\n",
    "    grayscale_count = 0\n",
    "    total_input_images = sum(len(images) for images in image_data.values())\n",
    "    \n",
    "    for class_name, images in image_data.items():\n",
    "        for img in images:\n",
    "            img_np = np.array(img)  # Convert image to NumPy array\n",
    "            \n",
    "            if len(img_np.shape) == 2:  # Grayscale image (only height and width)\n",
    "                grayscale_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Calculate the mean pixel intensity for each RGB channel\n",
    "            mean_channels = np.mean(img_np, axis=(0, 1))\n",
    "            \n",
    "            # Detect if any of the channels are outside their specific thresholds\n",
    "            condition = (mean_channels < [t[0] for t in thresholds]) | (mean_channels > [t[1] for t in thresholds])\n",
    "            if np.any(condition):\n",
    "                outliers.append(img)\n",
    "            else:\n",
    "                filtered_data[class_name].append(img)\n",
    "    \n",
    "    total_processed_images = sum(len(images) for images in filtered_data.values()) + len(outliers)\n",
    "    \n",
    "    print(f\"Input images: {total_input_images}\")\n",
    "    print(f\"Processed images: {total_processed_images}\")\n",
    "    print(f\"Removed Grayscale images: {grayscale_count}\")\n",
    "    print(f\"RGB images: {total_processed_images - grayscale_count}\")\n",
    "    print(f\"Outliers: {len(outliers)}\")\n",
    "    print(f\"Images in filtered_data: {sum(len(images) for images in filtered_data.values())}\")\n",
    "    \n",
    "    return dict(filtered_data), outliers\n",
    "\n",
    "# Define channel-specific thresholds based on the distributions\n",
    "thresholds = [\n",
    "    (27, 238),  # Red channel (low, high)\n",
    "    (14, 220),  # Green channel (low, high)\n",
    "    (8, 218)    # Blue channel (low, high)\n",
    "]\n",
    "\n",
    "# Use the optimized function with new thresholds\n",
    "filtered_data, rgb_outliers = detect_and_filter_rgb_outliers(filtered_data, thresholds)\n",
    "print(f'\\nFound {len(rgb_outliers)} potential RGB channel-based outliers out of {sum(len(images) for images in filtered_data.values()) + len(rgb_outliers)} total images.')\n",
    "print(f'Filtered data contains {sum(len(images) for images in filtered_data.values())} images after RGB channel-based filtering.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
